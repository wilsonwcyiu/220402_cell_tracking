# -*- coding: utf-8 -*-
"""Lineage_methods_Viterbi_visualize.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZAMApLe-8OPQt3EC0MwOK5r3EcYe_a-d
"""

from google.colab import drive
import os
from os import listdir
from os.path import join, basename
import numpy as np
from skimage import measure, filters
import matplotlib.pyplot as plt
from matplotlib import cm
from scipy.optimize import linear_sum_assignment
import copy
import time
import cv2
from google.colab.patches import cv2_imshow
import random
from itertools import combinations
import pickle

ROOT = '/content/drive/'     # default for the drive
drive.mount(ROOT)           # we mount the drive at /content/drive

PROJECT_PATH = '/content/drive/MyDrive'

"""# 新段落"""

segmentation_folder = '/content/drive/MyDrive/Tracking_simpledata2/Unet_trainingsets_simpledata2/data/segmentation/'
images_folder = '/content/drive/MyDrive/Tracking_simpledata2/Unet_trainingsets_simpledata2/data/images/'
output_folder = '/content/drive/MyDrive/Tracking_simpledata2/output_finetune_model_data2/'
video_folder = PROJECT_PATH + '/Tracking_simpledata2/video_tracks_finetune_data2_001/'
print(video_folder)

"""Tracking with viterbi slgorithm

Tracking with viterbi multiply and cut by threshold and loop
"""

from collections import defaultdict
def _find(start_list_index, start_list_value):
    store_dict = defaultdict(list)
    for k, v in start_list_value.items():
        #print(f'start from {k}-th sample:')
        current_step = len(v) - 1
        current_maximize_index = np.argmax(v[current_step])
        previous_maximize_index = start_list_index[k][current_step][current_maximize_index]
        store_dict[k].append((current_maximize_index, current_step + 2, previous_maximize_index))
        for i in range(len(v)-1):  
            # print(current_maximize_index)
            current_maximize_index_ = previous_maximize_index
            # previous_maximize_index = np.argmax(v[current_step - 1])
            previous_maximize_index_ = start_list_index[k][current_step - i - 1][current_maximize_index_]
            store_dict[k].append((current_maximize_index_, current_step + 1 - i, previous_maximize_index_))
            previous_maximize_index = previous_maximize_index_
        store_dict[k].append((previous_maximize_index_, 1, k))
        store_dict[k].append((k, 0, -1))
    for values in store_dict.values():
        values = list.reverse(values)
    
    return store_dict

def _find_iter(start_list_index, start_list_value, start_frame, node):
    global previous_maximize_index_1
    store_dict = defaultdict(list)
    for k, v in start_list_value.items():
        #print(f'start from {k}-th sample:')
        current_step = len(v) - 1
        current_maximize_index = np.argmax(v[current_step])
        previous_maximize_index = start_list_index[k][current_step][current_maximize_index]
        store_dict[k].append((current_maximize_index, start_frame + current_step + 2, previous_maximize_index))
        for i in range(len(v)-1):  
            # print(current_maximize_index)
            current_maximize_index_ = previous_maximize_index
            # previous_maximize_index = np.argmax(v[current_step - 1])
            previous_maximize_index_1 = start_list_index[k][current_step - i - 1][current_maximize_index_]
            store_dict[k].append((current_maximize_index_, start_frame + current_step + 1 - i, previous_maximize_index_1))
            previous_maximize_index = previous_maximize_index_1
        if len(v)!=1:
            store_dict[k].append((previous_maximize_index_1, start_frame + 1, node))
            store_dict[k].append((node, start_frame + 0, -1))
        else:
            store_dict[k].append((previous_maximize_index, start_frame + 1, node))
            store_dict[k].append((node, start_frame + 0, -1))
    for values in store_dict.values():
        values = list.reverse(values)
    
    return store_dict

# after got tracks, check if there are very lower prob between each two cells, then truncate it.
def _cut(longTracks, Threshold, transition_group):
    short_Tracks = {}
    for key, track in enumerate(longTracks):
        short_tracks = []
        for index in range(len(longTracks[key])-1):
            current_frame = longTracks[key][index][1]
            next_frame = longTracks[key][index+1][1]
            current_node = longTracks[key][index][0]
            next_node = longTracks[key][index+1][0]
            weight_between_nodes = transition_group[current_frame][current_node][next_node]
            if (weight_between_nodes > Threshold):
                short_tracks.append(longTracks[key][index])
            else:
                short_tracks = copy.deepcopy(longTracks[key][0:index])
                break
        if (len(short_tracks)==len(longTracks[key])-1):
            short_tracks.append(longTracks[key][-1])
            short_Tracks[key] = short_tracks
        else:
            short_tracks.append(longTracks[key][len(short_tracks)])
            short_Tracks[key] = short_tracks       
    return short_Tracks

def _cut_iter(longTracks, Threshold, transition_group, start_frame):
    short_Tracks = {}
    for key, track in enumerate(longTracks):
        short_tracks = []
        for index in range(len(longTracks[key])-1):
            current_frame = longTracks[key][index][1]
            next_frame = longTracks[key][index+1][1]
            if (index == 0):
                current_node = 0
                #print(transition_group[current_frame - start_frame].shape)
                transition_group[current_frame - start_frame] = transition_group[current_frame - start_frame].reshape(1,-1)
            else:
                current_node = longTracks[key][index][0]
            next_node = longTracks[key][index+1][0]
            weight_between_nodes = transition_group[current_frame - start_frame][current_node][next_node]
            if (weight_between_nodes > Threshold):
                short_tracks.append(longTracks[key][index])
            else:
                short_tracks = copy.deepcopy(longTracks[key][0:index])
                break
        if (len(short_tracks)==len(longTracks[key])-1):
            short_tracks.append(longTracks[key][-1])
            short_Tracks[key] = short_tracks
        else:
            short_tracks.append(longTracks[key][len(short_tracks)])
            short_Tracks[key] = short_tracks       
    return short_Tracks

def _mask(short_Tracks, transition_group):
    mask_transition_group = []
    # initialize the transition group with all False
    for prob_mat in transition_group:       
        mask_transition_group.append(np.array([False for i in range(prob_mat.shape[0])]))
    mask_transition_group.append(np.array([False for i in range(prob_mat.shape[1])]))
    # if the node was passed, lable it to True
    for kk, vv in short_Tracks.items():
        for iindex in range(len(short_Tracks[kk])):
            frame = short_Tracks[kk][iindex][1]
            node = short_Tracks[kk][iindex][0]
            mask_transition_group[frame][node] = True
    
    return mask_transition_group

def _mask_update(short_Tracks, mask_transition_group):
    # if the node was passed, lable it to True
    for kk, vv in short_Tracks.items():
        for iindex in range(len(short_Tracks[kk])):
            frame = short_Tracks[kk][iindex][1]
            node = short_Tracks[kk][iindex][0]
            mask_transition_group[frame][node] = True
    
    return mask_transition_group

def _iteration(transition_group):
    all_tracks = {}
    start_list_index, start_list_value = _process(transition_group)
    store_dict = _find(start_list_index, start_list_value)
    short_Tracks = _cut(store_dict, 0.001, transition_group)
    all_tracks.update(short_Tracks)
    length = len(all_tracks)
    mask_transition_group =  _mask(short_Tracks, transition_group)
    for p_matrix in range(1,len(transition_group)):
        #print(transition_group[p_matrix].shape)
        #print(transition_group[p_matrix].shape[0])
        for node in range(transition_group[p_matrix].shape[0]):  #skip all nodes which are already passed 
            #print(node)
            if (mask_transition_group[p_matrix][node]==True):
                continue
            else:
                new_transition_group = []
                new_transition_group_ = transition_group[p_matrix:]
                new_transition_group.append(new_transition_group_[0][node])
                new_transition_group[1:] = transition_group[p_matrix+1:]
                next_list_index, next_list_value = _process_iter(new_transition_group)
                new_store_dict = _find_iter(next_list_index, next_list_value, p_matrix, node)
                new_short_Tracks = _cut_iter(new_store_dict, 0.001, new_transition_group, p_matrix)
            mask_transition_group =  _mask_update(new_short_Tracks, mask_transition_group)
            for ke, val in new_short_Tracks.items():
                all_tracks[length + ke] = val
            length = len(all_tracks)
    return all_tracks

def _process(transition_group):
    step = len(transition_group)
    start_list_index = defaultdict(list)
    start_list_value = defaultdict(list)

    for ii, item in enumerate(transition_group[0]):
        for i in range(1, step):          
            item = item[:, np.newaxis]
            item = np.repeat(item, transition_group[i].shape[1], 1)
            index_ab = np.argmax(item * transition_group[i], 0)
            value_ab = np.max(item * transition_group[i], 0)
            if (np.all(value_ab==0)):
                break
            start_list_index[ii].append(index_ab)
            start_list_value[ii].append(value_ab)
            item = value_ab
    return start_list_index, start_list_value

def _process_iter(transition_group):
    step = len(transition_group)
    start_list_index = defaultdict(list)
    start_list_value = defaultdict(list)
    
    for ii, item in enumerate(transition_group[0].reshape(1, transition_group[0].shape[0])):
        for i in range(1, step):                  
            item = item[:, np.newaxis]
            item = np.repeat(item, transition_group[i].shape[1], 1)
            index_ab = np.argmax(item * transition_group[i], 0)
            value_ab = np.max(item * transition_group[i], 0)
            if (np.all(value_ab==0)):
                break
            start_list_index[ii].append(index_ab)
            start_list_value[ii].append(value_ab)
            item = value_ab
    return start_list_index, start_list_value


viterbi_results_dict02 = {   
    "S09": [],
    #"S03": [], 
}

series = ['S09'] # enter all tracked images series
#celltypes = ['C1'] # enter all tracked celllines

#all tracks shorter than DELTA_TIME are false postives and not included in tracks
DELTA_TIME = 5 
result = []

segmented_files = listdir(segmentation_folder)
segmented_files.sort()
for serie in series:
    #if data is not complete
    if not serie in listdir(output_folder):
        continue 
    #for celltype in celltypes:
    print(serie)
    filelist = []
    img_list = []
    label_img_list = []
    #select all files of the current images series and celltype
    for filename in segmented_files:
        if serie in filename:
            filelist = filelist + [filename]

    C = []
    prof_mat_list = []
    #get the first image (frame 0) and label the cells:
    img = plt.imread(segmentation_folder + filelist[0])
    img_list.append(img)
    label_img = measure.label(img, background=0,connectivity=1)
    label_img_list.append(label_img)
    cellnb_img = np.max(label_img)
        
    for framenb in range(1,len(filelist)):
        #get next frame and number of cells next frame
        img_next = plt.imread(segmentation_folder +'/' + filelist[framenb])
        img_list.append(img_next)
        label_img_next = measure.label(img_next, background=0,connectivity=1)
        label_img_list.append(label_img_next)
        cellnb_img_next = np.max(label_img_next)

        #prof_size = max(cellnb_img, cellnb_img_next)
        #create empty dataframe for element of profit matrix C
        prof_mat = np.zeros((cellnb_img, cellnb_img_next), dtype=float)

        #loop through all combinations of cells in this and the next frame
        for cellnb_i in range(cellnb_img):
            #cellnb i + 1 because cellnumbering in output files starts from 1
            cell_i_filename = "mother_" + filelist[framenb][:-4] + "_Cell" + str(cellnb_i+1).zfill(2) + ".png"
            cell_i = plt.imread(output_folder + serie +'/' + cell_i_filename)
            #predictions are for each cell in curr img
            cell_i_props = measure.regionprops(label_img_next,intensity_image=cell_i) #label_img_next是二值图像为255，无intensity。需要与output中的预测的细胞一一对应，预测细胞有intensity
            for cellnb_j in range(cellnb_img_next):
                #calculate profit score from mean intensity neural network output in segmented cell area
                prof_mat[cellnb_i,cellnb_j] = cell_i_props[cellnb_j].mean_intensity         #得到填充矩阵size = max(cellnb_img, cellnb_img_next)：先用预测的每一个细胞的mean_intensity填满cellnb_img, cellnb_img_next行和列

        #prof_mat = prof_mat/np.max(prof_mat)    #np.max 矩阵中的最大数值 归一化
        prof_mat = prof_mat
        prof_mat_list.append(prof_mat)

        #make next frame current frame
        cellnb_img = cellnb_img_next
        label_img = label_img_next
    #print(len(C))
    #result = tracking(C, prof_mat_list, DELTA_TIME)
    all_tracks = _iteration(prof_mat_list)
    
    result = []    
    for i in range(len(all_tracks)):
        #print(store_dict[i])
        #result.append(all_tracks[i])
        if (len(all_tracks[i])>5):
            result.append(all_tracks[i])
    #print(result)
    identifier = serie
    viterbi_results_dict02[identifier] = result
"""
'''save track dictionary'''
def save_track_dictionary(dictionary, save_file):
    if not os.path.exists(save_file):
        with open(save_file, 'w'):
            pass
    pickle_out = open(save_file,"wb")
    pickle.dump(dictionary,pickle_out)
    pickle_out.close()

save_dir =PROJECT_PATH + '/Tracking/track_dicts_dis_bin_weight40/viterbi/' 
print(save_dir)
save_track_dictionary(viterbi_results_dict, save_dir + "viterbi_results_dict.pkl")
"""

"""Save algorithms as dicts"""

'''save track dictionary'''
def save_track_dictionary(dictionary, save_file):
    if not os.path.exists(save_file):
        with open(save_file, 'w'):
            pass
    pickle_out = open(save_file,"wb")
    pickle.dump(dictionary,pickle_out)
    pickle_out.close()

save_dir =PROJECT_PATH + '/Tracking_simpledata2/track_dicts_finetunemodel_data2_001/' 
print(save_dir)
save_track_dictionary(viterbi_results_dict02, save_dir + "viterbi_results_dict02.pkl")
#save_track_dictionary(viterbi_results_dict2, save_dir + "viterbi_results_dict2.pkl")
#save_track_dictionary(viterbi_results_dict, save_dir + "viterbi_results_dict.pkl")

'''opening a track dictionary from file'''
def open_track_dictionary(save_file):
    pickle_in = open(save_file,"rb")
    dictionary = pickle.load(pickle_in)
    return dictionary

save_dir = PROJECT_PATH + '/Tracking_simpledata2/track_dicts_finetunemodel_data2_001/'
#viterbi_results_dict3_finetune = open_track_dictionary(save_dir + "viterbi_results_dict3_finetune.pkl")
viterbi_results_dict = open_track_dictionary(save_dir + "viterbi_results_dict_finetune.pkl")
viterbi_results_dict2 = open_track_dictionary(save_dir + "viterbi_results_dict2_finetune.pkl")

"""Draw and plot tracks"""

'''draw and save plotted tracks'''
np.set_printoptions(edgeitems=30, linewidth=100000)

#get a slightly darker colour for the points indicating the current track
def get_point_color(color):
    point_color = tuple(np.subtract(color, (20,20,20)))
    point_color= tuple([int(i) for i in point_color])
    return point_color

#print (& save) the cell tracks in each frame for a max number of TRACK_LENGTH frames
def draw_and_save_tracks(results_dict, segmentation_folder, video_folder, SAVE, TRACK_LENGTH):
    for identifier, result in results_dict.items():
        print(identifier)
        serie = identifier
        print(serie)

        #get the correct segementation files
        segmented_files = listdir(segmentation_folder)
        segmented_files.sort()
        filelist = []
        
        #select all files of the current images series and celltype
        for filename in segmented_files:
            if serie in filename:
                filelist = filelist + [filename]

        img_list = []
        labeled_img_list = []
        for framenb in range(len(filelist)):
            img = cv2.imread(segmentation_folder + '/' + filelist[framenb])
            label_img = measure.label(img, background=0,connectivity=1)
            img_list.append(img)
            labeled_img_list.append(label_img)

        #create a list to select random colours for tracks from
        colorlist = []
        random.seed(23)
        for i in range(len(result)):
            r = random.randint(30,255)
            g = random.randint(30,255)
            b = random.randint(30,255)
            colorlist.append((r,g,b))

        #loop through all tracked frames to create the tracked images
        for framenb in range(len(filelist)):
            print(framenb)
            img = img_list[framenb]
            for tracknb, track in enumerate(result):
                
                frames_in_track = np.array(list(zip(*track))[1])
                
                #do not print track if not in current frame
                if not framenb in frames_in_track:
                    continue
                
                #get part of current track for a maximum of TRACK_LENGTH frames back to the current frame 
                partial_track_idx = np.where((frames_in_track <= framenb) & (frames_in_track >= framenb-TRACK_LENGTH))
                
                #print line piece for every cell in partial track
                for cell_idx in partial_track_idx[0]:
                    cell_idx = int(cell_idx)
                    props = measure.regionprops(labeled_img_list[track[cell_idx][1]])
                    cell_coord_y, cell_coord_x,_ = props[track[cell_idx][0]].centroid
                    
                    #print a dot at current cell position
                    if track[cell_idx][1] == framenb:
                        cv2.circle(img,(int(cell_coord_x),int(cell_coord_y)), 2, get_point_color(colorlist[tracknb]), -1)
                        # cv2.putText(img, str(track[cell_idx][0]), (int(cell_coord_x),int(cell_coord_y-10)), cv2.FONT_HERSHEY_COMPLEX,0.4,(147,20,255),1) 
                    
                    #skip first frame
                    if track[cell_idx][2] == -1:
                        continue
                    
                    #get coordinates of previous cellposition from track
                    i = 1
                    while True:
                        if track[cell_idx][2] == track[cell_idx-i][0]:
                            props = measure.regionprops(labeled_img_list[track[cell_idx][1]-1])
                            prev_cell_coord_y, prev_cell_coord_x,_ = props[track[cell_idx-i][0]].centroid
                            break
                        else:
                            i = i+1
                                    
                    cv2.line(img, (int(prev_cell_coord_x), int(prev_cell_coord_y)), (int(cell_coord_x), int(cell_coord_y)), colorlist[tracknb])
            cv2_imshow(img)
            #save the created images
            if SAVE:
                results_dir = video_folder + serie + '/'
                if not os.path.isdir(results_dir):
                    os.makedirs(results_dir)
                cv2.imwrite(results_dir + '/' + str(framenb) +'.png', img) 

#settings
TRACK_LENGTH = 30
SAVE = True
video_folder_name = video_folder + '/viterbi_results_dict/'
"""
viterbi_results_dict3_finetune
keys = ('S04','S05')
viterbi_results_dict_slice = {k: viterbi_results_dict3_finetune[k] for k in keys}
print(viterbi_results_dict_slice.keys())
"""
draw_and_save_tracks(viterbi_results_dict, segmentation_folder, video_folder_name, SAVE, TRACK_LENGTH)